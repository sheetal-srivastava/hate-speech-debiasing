{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7856158,"sourceType":"datasetVersion","datasetId":4607830}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pickle\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T03:03:22.788333Z","iopub.execute_input":"2024-03-16T03:03:22.789197Z","iopub.status.idle":"2024-03-16T03:03:22.793992Z","shell.execute_reply.started":"2024-03-16T03:03:22.789166Z","shell.execute_reply":"2024-03-16T03:03:22.793137Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Confirm that the GPU is detected\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T02:55:26.848995Z","iopub.execute_input":"2024-03-16T02:55:26.849329Z","iopub.status.idle":"2024-03-16T02:55:26.905662Z","shell.execute_reply.started":"2024-03-16T02:55:26.849303Z","shell.execute_reply":"2024-03-16T02:55:26.904720Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Get the GPU device name.\ndevice_name = torch.cuda.get_device_name()\nn_gpu = torch.cuda.device_count()\nprint(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\ndevice = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T02:55:26.907558Z","iopub.execute_input":"2024-03-16T02:55:26.908483Z","iopub.status.idle":"2024-03-16T02:55:26.918571Z","shell.execute_reply.started":"2024-03-16T02:55:26.908456Z","shell.execute_reply":"2024-03-16T02:55:26.917511Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found device: Tesla T4, n_gpu: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data used from the following source: https://aclanthology.org/2020.emnlp-main.473/ \n\naave_csv = pd.read_csv(\"/kaggle/input/dialect-samples/aave_samples.csv\",header=None)\nsae_csv = pd.read_csv(\"/kaggle/input/dialect-samples/sae_samples.csv\",header=None)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:03:27.878622Z","iopub.execute_input":"2024-03-16T03:03:27.879504Z","iopub.status.idle":"2024-03-16T03:03:27.908035Z","shell.execute_reply.started":"2024-03-16T03:03:27.879468Z","shell.execute_reply":"2024-03-16T03:03:27.907265Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"> The AAE to SAE translation samples dataset is obtained from the [Groenwold et al., EMNLP 2020](http://https://aclanthology.org/2020.emnlp-main.473/) paper.","metadata":{}},{"cell_type":"code","source":"aave_csv.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:03:30.425456Z","iopub.execute_input":"2024-03-16T03:03:30.425837Z","iopub.status.idle":"2024-03-16T03:03:30.434500Z","shell.execute_reply.started":"2024-03-16T03:03:30.425804Z","shell.execute_reply":"2024-03-16T03:03:30.433536Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                   0\n0  Sooo Manti Te'o was having a online/phone rela...\n1  this lil girl aint going to win im the king of...\n2  He up stairs rights now and I'm down here gett...\n3  Shit I Am Who Am..Fresh up out of Apologize..I...\n4  It's very rare that I get what I want. Now tha...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sooo Manti Te'o was having a online/phone rela...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>this lil girl aint going to win im the king of...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He up stairs rights now and I'm down here gett...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Shit I Am Who Am..Fresh up out of Apologize..I...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It's very rare that I get what I want. Now tha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sae_csv.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:03:32.263090Z","iopub.execute_input":"2024-03-16T03:03:32.263468Z","iopub.status.idle":"2024-03-16T03:03:32.272136Z","shell.execute_reply.started":"2024-03-16T03:03:32.263438Z","shell.execute_reply":"2024-03-16T03:03:32.271209Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                   0\n0  Manti Te'o was having a relationship via telep...\n1  The little girl is not going to win because i ...\n2  He is upstairs rights now and I'm down here ge...\n3  Shit, I am who I am. I'm done apologizing. I'm...\n4  It is very rare that I get what I want, but no...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Manti Te'o was having a relationship via telep...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The little girl is not going to win because i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He is upstairs rights now and I'm down here ge...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Shit, I am who I am. I'm done apologizing. I'm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It is very rare that I get what I want, but no...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"aave_csv.rename(columns = {0:'AAVE'},inplace = True)\nsae_csv.rename(columns = {0:'SAE'},inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:03:34.480353Z","iopub.execute_input":"2024-03-16T03:03:34.480672Z","iopub.status.idle":"2024-03-16T03:03:34.486485Z","shell.execute_reply.started":"2024-03-16T03:03:34.480648Z","shell.execute_reply":"2024-03-16T03:03:34.485574Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"merged_df = pd.concat([aave_csv, sae_csv], axis=1)\nmerged_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:03:35.620287Z","iopub.execute_input":"2024-03-16T03:03:35.620634Z","iopub.status.idle":"2024-03-16T03:03:35.630661Z","shell.execute_reply.started":"2024-03-16T03:03:35.620608Z","shell.execute_reply":"2024-03-16T03:03:35.629722Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                AAVE  \\\n0  Sooo Manti Te'o was having a online/phone rela...   \n1  this lil girl aint going to win im the king of...   \n2  He up stairs rights now and I'm down here gett...   \n3  Shit I Am Who Am..Fresh up out of Apologize..I...   \n4  It's very rare that I get what I want. Now tha...   \n\n                                                 SAE  \n0  Manti Te'o was having a relationship via telep...  \n1  The little girl is not going to win because i ...  \n2  He is upstairs rights now and I'm down here ge...  \n3  Shit, I am who I am. I'm done apologizing. I'm...  \n4  It is very rare that I get what I want, but no...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AAVE</th>\n      <th>SAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sooo Manti Te'o was having a online/phone rela...</td>\n      <td>Manti Te'o was having a relationship via telep...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>this lil girl aint going to win im the king of...</td>\n      <td>The little girl is not going to win because i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He up stairs rights now and I'm down here gett...</td>\n      <td>He is upstairs rights now and I'm down here ge...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Shit I Am Who Am..Fresh up out of Apologize..I...</td>\n      <td>Shit, I am who I am. I'm done apologizing. I'm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It's very rare that I get what I want. Now tha...</td>\n      <td>It is very rare that I get what I want, but no...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into training and testing\ntrain_df, test_df = train_test_split(merged_df, test_size=0.1)\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:04:06.096809Z","iopub.execute_input":"2024-03-16T03:04:06.097438Z","iopub.status.idle":"2024-03-16T03:04:06.214124Z","shell.execute_reply.started":"2024-03-16T03:04:06.097406Z","shell.execute_reply":"2024-03-16T03:04:06.213203Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(train_dataset), len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:04:13.463384Z","iopub.execute_input":"2024-03-16T03:04:13.463731Z","iopub.status.idle":"2024-03-16T03:04:13.469798Z","shell.execute_reply.started":"2024-03-16T03:04:13.463704Z","shell.execute_reply":"2024-03-16T03:04:13.468892Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(1817, 202)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training MBart to perform AAE-to-SAE translation","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('facebook/mbart-large-en-ro')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:05:24.120277Z","iopub.execute_input":"2024-03-16T03:05:24.121208Z","iopub.status.idle":"2024-03-16T03:05:27.075661Z","shell.execute_reply.started":"2024-03-16T03:05:24.121163Z","shell.execute_reply":"2024-03-16T03:05:27.074600Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e1e9bd23f44900bccf76eefa700729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931c4e8a87154b0b9e45b1b7e9f19d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821dafe0464547d89909128085848ad7"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    # Tokenize both the AAE (input) and SAE (target) sentences.\n    model_inputs = tokenizer(examples[\"AAVE\"], max_length=128, padding=\"max_length\", truncation=True)\n\n    # Tokenize the labels without using return_tensors=\"pt\" to keep them as lists\n    labels = tokenizer(examples[\"SAE\"], max_length=128, padding=\"max_length\", truncation=True)\n    \n    # Update model_inputs to include labels; ensure labels are lists\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    \n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:05:41.853826Z","iopub.execute_input":"2024-03-16T03:05:41.854504Z","iopub.status.idle":"2024-03-16T03:05:41.860160Z","shell.execute_reply.started":"2024-03-16T03:05:41.854471Z","shell.execute_reply":"2024-03-16T03:05:41.859201Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Mapping the tokenization function over the datasets.\ntokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\ntokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:05:51.007563Z","iopub.execute_input":"2024-03-16T03:05:51.007908Z","iopub.status.idle":"2024-03-16T03:05:51.562863Z","shell.execute_reply.started":"2024-03-16T03:05:51.007881Z","shell.execute_reply":"2024-03-16T03:05:51.561981Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1ff72ec18d94ee5a48931406fe8f7c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5195c4e7851045bb9052d91448b6aebf"}},"metadata":{}}]},{"cell_type":"code","source":"# Inspect the first few examples from the tokenized training dataset\nfor i in range(5):\n    print(\"AAVE:\", tokenizer.decode(tokenized_train_dataset[i]['input_ids'], skip_special_tokens=True))\n    print(\"SAE:\", tokenizer.decode(tokenized_train_dataset[i]['labels'], skip_special_tokens=True), '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:06:08.842754Z","iopub.execute_input":"2024-03-16T03:06:08.843399Z","iopub.status.idle":"2024-03-16T03:06:08.868530Z","shell.execute_reply.started":"2024-03-16T03:06:08.843364Z","shell.execute_reply":"2024-03-16T03:06:08.867505Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"AAVE: 's message \"I will give you rest\" must of worked last night - found stress ball under a chair inthe worship center this morning.\nSAE: the message \\\"I will give you rest\\\" must have worked last night. I found a stress ball under a chair in the worship center this morning \n\nAAVE: Whatup, I'm cool. Just been staying out the way. How youand that lil lady doing?\nSAE: Hello, I'm doing well. I've just been behaving myself and staying out of trouble. How are youand your wife doing \n\nAAVE: Never SHOW A Man That Your A Good Woman Cus OBVIOUSLY He's Gonna Take Advantage Of It, LET HIMLEARN && EARN POINTS!\nSAE: Don't ever show a man that you're a good woman because they obviously will take advantage of it, let himfind out on his own and respect you for what you are \n\nAAVE: I never liked Gucci. now everybody sees the royal flop ness monster! He been weak. It shouldn't have taken his breakdownfor it 2 b known\nSAE: I never liked Gucci. Now everybody can sees the \\\"Royal Flop Ness Monster\\\"! He has been bad, it shouldn't have taken his breakdownfor it to be known \n\nAAVE: MissSt on Saturday. Time for conference play. We've improved every week. Time tolay it on the field\nSAE: Mississippi State on Saturday. Time for conference play. We've improved every week. Time tolay it on the field \n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained('facebook/mbart-large-en-ro', device_map='auto')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:06:24.865577Z","iopub.execute_input":"2024-03-16T03:06:24.866295Z","iopub.status.idle":"2024-03-16T03:06:34.870469Z","shell.execute_reply.started":"2024-03-16T03:06:24.866264Z","shell.execute_reply":"2024-03-16T03:06:34.869721Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb31731c6eda4fa1835864a8309dc04a"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',          # directory for saving models and checkpoints\n    num_train_epochs=5,              # number of training epochs, adjust as needed\n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:06:41.281383Z","iopub.execute_input":"2024-03-16T03:06:41.282265Z","iopub.status.idle":"2024-03-16T03:06:41.290826Z","shell.execute_reply.started":"2024-03-16T03:06:41.282203Z","shell.execute_reply":"2024-03-16T03:06:41.290051Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:06:48.709024Z","iopub.execute_input":"2024-03-16T03:06:48.709401Z","iopub.status.idle":"2024-03-16T03:06:50.142203Z","shell.execute_reply.started":"2024-03-16T03:06:48.709368Z","shell.execute_reply":"2024-03-16T03:06:50.141249Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"> Takes ~20 minutes to train for 5 epochs over ~1.8k samples","metadata":{}},{"cell_type":"code","source":"trainer.train()  ","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:06:59.868193Z","iopub.execute_input":"2024-03-16T03:06:59.869029Z","iopub.status.idle":"2024-03-16T03:26:26.797206Z","shell.execute_reply.started":"2024-03-16T03:06:59.868995Z","shell.execute_reply":"2024-03-16T03:26:26.796291Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112792277776862, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bed42133e7d7478d95bdd57386c3e1bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240316_030723-2hats68z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/responsible-ds/huggingface/runs/2hats68z' target=\"_blank\">zany-glitter-7</a></strong> to <a href='https://wandb.ai/responsible-ds/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/responsible-ds/huggingface' target=\"_blank\">https://wandb.ai/responsible-ds/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/responsible-ds/huggingface/runs/2hats68z' target=\"_blank\">https://wandb.ai/responsible-ds/huggingface/runs/2hats68z</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [570/570 18:23, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>10.723400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>10.056300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>9.561200</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>9.329700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>9.000100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>8.650700</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>8.256900</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>7.773700</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>7.363300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>6.706200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>6.114100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>5.399600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>4.684500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>3.981700</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.163600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.276600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.536700</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.915000</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.643100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.485400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.449300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.372400</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.371400</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.328600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.319700</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.310800</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.282600</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.309600</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.306300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.293900</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.279400</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.304400</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.286900</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.307400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.216800</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.163100</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.179100</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.195700</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.183000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.191600</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.210800</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.185000</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.194900</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.202200</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.203100</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.171200</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.123000</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.117200</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.112000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.115900</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.123300</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.110100</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.116800</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.118000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.120900</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.124600</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.117400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 1024, 'num_beams': 5, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=570, training_loss=2.1884235172940976, metrics={'train_runtime': 1166.455, 'train_samples_per_second': 7.789, 'train_steps_per_second': 0.489, 'total_flos': 2461046742712320.0, 'train_loss': 2.1884235172940976, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate(eval_dataset=tokenized_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:44:03.212567Z","iopub.execute_input":"2024-03-16T03:44:03.213672Z","iopub.status.idle":"2024-03-16T03:44:12.400578Z","shell.execute_reply.started":"2024-03-16T03:44:03.213639Z","shell.execute_reply":"2024-03-16T03:44:12.399370Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 00:08]\n    </div>\n    "},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.36918875575065613,\n 'eval_runtime': 9.1737,\n 'eval_samples_per_second': 22.019,\n 'eval_steps_per_second': 1.417,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"model_fname = 'mbart_translate_5epochs.sav'\n\n# Save the model to disk\npickle.dump(model, open(model_fname, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:44:14.895266Z","iopub.execute_input":"2024-03-16T03:44:14.896064Z","iopub.status.idle":"2024-03-16T03:44:19.499965Z","shell.execute_reply.started":"2024-03-16T03:44:14.896033Z","shell.execute_reply":"2024-03-16T03:44:19.498941Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Get the file download link manually \n\n%cd /kaggle/working\n\nfrom IPython.display import FileLink \nFileLink(model_fname)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:44:32.265573Z","iopub.execute_input":"2024-03-16T03:44:32.265920Z","iopub.status.idle":"2024-03-16T03:44:32.277462Z","shell.execute_reply.started":"2024-03-16T03:44:32.265894Z","shell.execute_reply":"2024-03-16T03:44:32.276433Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/mbart_translate_5epochs.sav","text/html":"<a href='mbart_translate_5epochs.sav' target='_blank'>mbart_translate_5epochs.sav</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Demo: AAE to SAE translation example using MBart","metadata":{}},{"cell_type":"code","source":"# Load the model from disk\n\nfilename = '/kaggle/working/' + model_fname\ntranslation_model = pickle.load(open(filename, 'rb'))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:46:16.779996Z","iopub.execute_input":"2024-03-16T03:46:16.780418Z","iopub.status.idle":"2024-03-16T03:46:20.185935Z","shell.execute_reply.started":"2024-03-16T03:46:16.780347Z","shell.execute_reply":"2024-03-16T03:46:20.184973Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def translate_aae_to_sae(sentence, model, tokenizer, device='cuda'):\n    # Move the model to the specified device\n    model.to(device)\n\n    # Tokenize the input sentence\n    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Move the input tensors to the same device as the model\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n\n    # Generate translation output\n    output_sequences = model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        max_length=256,\n    )\n\n    # Decode the output\n    translated_sentence = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n    return translated_sentence","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:46:38.262475Z","iopub.execute_input":"2024-03-16T03:46:38.262851Z","iopub.status.idle":"2024-03-16T03:46:38.273554Z","shell.execute_reply.started":"2024-03-16T03:46:38.262823Z","shell.execute_reply":"2024-03-16T03:46:38.272286Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"aae_sentence = \"Where you been\"\nsae_translation = translate_aae_to_sae(aae_sentence, translation_model, tokenizer)\nprint(f\"AAE: {aae_sentence}\\nSAE: {sae_translation}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:47:19.323811Z","iopub.execute_input":"2024-03-16T03:47:19.324631Z","iopub.status.idle":"2024-03-16T03:47:19.497093Z","shell.execute_reply.started":"2024-03-16T03:47:19.324598Z","shell.execute_reply":"2024-03-16T03:47:19.496145Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"AAE: Where you been\nSAE: Where are you been?\n","output_type":"stream"}]},{"cell_type":"code","source":"aae_sentence = \"Boy you can say anything you wanna I don't give a shit, noone else can have ya\"\nsae_translation = translate_aae_to_sae(aae_sentence, translation_model, tokenizer)\nprint(f\"AAE: {aae_sentence}\\nSAE: {sae_translation}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:47:20.920138Z","iopub.execute_input":"2024-03-16T03:47:20.920944Z","iopub.status.idle":"2024-03-16T03:47:21.505121Z","shell.execute_reply.started":"2024-03-16T03:47:20.920903Z","shell.execute_reply":"2024-03-16T03:47:21.504155Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"AAE: Boy you can say anything you wanna I don't give a shit, noone else can have ya\nSAE: You can say anything you want to, I don't give a shit. Noone else can have you\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}